{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonian import HamiltonianSmall, Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lih_small = HamiltonianSmall('LiH', 1.5) # this encoding uses reduction techniques\n",
    "beh2_small = HamiltonianSmall('BeH2', 1.3) # this encoding uses reduction techniques\n",
    "\n",
    "# 4 qubits\n",
    "h2_jw_4 = Hamiltonian('H2_STO3g_4qubits', 'jw')\n",
    "h2_parity_4 = Hamiltonian('H2_STO3g_4qubits', 'parity')\n",
    "h2_bk_4 = Hamiltonian('H2_STO3g_4qubits', 'bk')\n",
    "\n",
    "# 8 qubits\n",
    "h2_jw = Hamiltonian('H2_6-31G_8qubits', 'jw')\n",
    "h2_parity = Hamiltonian('H2_6-31G_8qubits', 'parity')\n",
    "h2_bk = Hamiltonian('H2_6-31G_8qubits', 'bk')\n",
    "\n",
    "# 12 qubits\n",
    "lih_jw = Hamiltonian('LiH_STO3g_12qubits', 'jw')\n",
    "lih_parity = Hamiltonian('LiH_STO3g_12qubits', 'parity')\n",
    "lih_bk = Hamiltonian('LiH_STO3g_12qubits', 'bk')\n",
    "\n",
    "# 14 qubits\n",
    "h2o_jw = Hamiltonian('H2O_STO3g_14qubits', 'jw')\n",
    "h2o_parity = Hamiltonian('H2O_STO3g_14qubits', 'parity')\n",
    "h2o_bk = Hamiltonian('H2O_STO3g_14qubits', 'bk')\n",
    "\n",
    "beh2_jw = Hamiltonian('BeH2_STO3g_14qubits', 'jw')\n",
    "beh2_parity = Hamiltonian('BeH2_STO3g_14qubits', 'parity')\n",
    "beh2_bk = Hamiltonian('BeH2_STO3g_14qubits', 'bk')\n",
    "\n",
    "# 16 qubits\n",
    "nh3_jw = Hamiltonian('NH3_STO3g_16qubits', 'jw')\n",
    "nh3_parity = Hamiltonian('NH3_STO3g_16qubits', 'parity')\n",
    "nh3_bk = Hamiltonian('NH3_STO3g_16qubits', 'bk')\n",
    "\n",
    "# 20 qubits\n",
    "c2_jw = Hamiltonian('C2_STO3g_20qubits', 'jw')\n",
    "c2_parity = Hamiltonian('C2_STO3g_20qubits', 'parity')\n",
    "c2_bk = Hamiltonian('C2_STO3g_20qubits', 'bk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltonians = {\"lih_small\": lih_small,\n",
    "                \"beh2_small\": beh2_small,\n",
    "                \"h2_jw_4\": h2_jw_4,\n",
    "                \"h2_parity_4\": h2_parity_4,\n",
    "                \"h2_bk_4\": h2_bk_4,\n",
    "                \"h2_jw\": h2_jw,\n",
    "                \"h2_parity\": h2_parity,\n",
    "                \"h2_bk\": h2_bk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time h2_jw_4.pauli_rep.ground()\n",
    "%time h2_jw.pauli_rep.ground()\n",
    "%time lih_jw.pauli_rep.ground()\n",
    "%time energy, state = h2o_jw.pauli_rep.ground()\n",
    "# %time energy, state = nh3_jw.pauli_rep.ground() # takes about 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time h2_jw_4.pauli_rep.ground(multithread=True)\n",
    "%time h2_jw.pauli_rep.ground(multithread=True)\n",
    "%time lih_jw.pauli_rep.ground(multithread=True)\n",
    "%time energy, state = h2o_jw.pauli_rep.ground(multithread=True)\n",
    "# %time energy, state = ammonia_jw.pauli_rep.ground(multithread=True) # takes about 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance formula\n",
    "\n",
    "\\begin{align}\n",
    "    \\Var[\\nu] \n",
    "    &=\n",
    "    \\sum_{\\Qarrow,\\Rarrow}\n",
    "        f_\\beta(\\Qarrow,\\Rarrow)\n",
    "        \\alpha_\\Qarrow \\alpha_\\Rarrow\n",
    "        \\tr(\\rho\\Qarrow\\Rarrow)\n",
    "    - \\tr(\\rho H_0 )^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = h2_jw_4\n",
    "energy, state = ham.pauli_rep.ground()\n",
    "β = ham.pauli_rep.local_dists_uniform()\n",
    "%time ham.pauli_rep.variance_local(energy, state, β)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ell_1: \", ham.pauli_rep.variance_ell_1(energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is from an old idea, which ultimately did not work well.\n",
    "\n",
    "β = ham.pauli_rep.local_dists_pnorm(1)\n",
    "print(\"1_norm: \", ham.pauli_rep.variance_local(energy, state, β))\n",
    "\n",
    "β = ham.pauli_rep.local_dists_pnorm(2)\n",
    "print(\"2_norm: \", ham.pauli_rep.variance_local(energy, state, β))\n",
    "\n",
    "β = ham.pauli_rep.local_dists_pnorm('infinity')\n",
    "print(\"max_norm: \", ham.pauli_rep.variance_local(energy, state, β))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance optimisation (method=diagonal)\n",
    "\n",
    "This is not the correct optimisation. However it\n",
    "- gives good results;\n",
    "- is quicker than the full optimisation problem;\n",
    "- is convex (so local minimums are global);\n",
    "- does not need access to the Hartree-Fock bitstring for the encoding.\n",
    "\n",
    "Diagonal minimisation asks us to find $\\{\\beta_{i,P}\\}$ in order to minimise:\n",
    "$$\n",
    "    \\sum_{\\Qarrow} \\alpha_\\Qarrow^2 \\prod_{i\\in\\supp(\\Qarrow)} \\beta_{i,Q_i}^{-1}\n",
    "    \\qquad\n",
    "    \\textrm{subject to}\n",
    "    \\qquad\n",
    "    \\beta_{i,X}+\\beta_{i,Y}+\\beta_{i,Z}=1 \\,\\forall i,\n",
    "    \\qquad\n",
    "    \\beta_{i,P}\\ge 0\n",
    "$$\n",
    "\n",
    "And we have an implementation using Lagrange multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β = ham.pauli_rep.local_dists_optimal('diagonal', 'scipy')\n",
    "print(ham.pauli_rep.variance_local(energy, state, β))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β = ham.pauli_rep.local_dists_optimal('diagonal', 'lagrange')\n",
    "print(ham.pauli_rep.variance_local(energy, state, β))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 7.32 s, total: 1min 11s\n",
      "Wall time: 12 s\n",
      "CPU times: user 2.25 s, sys: 67.7 ms, total: 2.32 s\n",
      "Wall time: 1.74 s\n",
      "discrepancy between variances:  4.931720458856148e-05\n"
     ]
    }
   ],
   "source": [
    "# time comparison lih_jw has 12 qubits\n",
    "\n",
    "ham = lih_jw\n",
    "%time β_scipy = ham.pauli_rep.local_dists_optimal('diagonal', 'scipy')\n",
    "%time β_lagrange = ham.pauli_rep.local_dists_optimal('diagonal', 'lagrange')\n",
    "\n",
    "energy, state = ham.pauli_rep.ground(multithread=True)\n",
    "var_scipy = ham.pauli_rep.variance_local(energy, state, β_scipy)\n",
    "var_lagrange = ham.pauli_rep.variance_local(energy, state, β_lagrange)\n",
    "\n",
    "discrepancy = abs(var_scipy - var_lagrange)\n",
    "print(\"discrepancy between variances: \", discrepancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance optimisation (method=mixed)\n",
    "\n",
    "This is the full optimisation problem. It requires access to the Hartree-Fock bitstring $m$ or `bitstring_HF` so that the HF state reads\n",
    "$\\frac1{2^n}\\otimes_{i=1}^n (I+m_i Z)$\n",
    "\n",
    "In the JW encoding these are:\n",
    "- H2 = `1010` (on four qubits)\n",
    "- H2 = `10001000`\n",
    "- LiH = `100000100000`\n",
    "- H2O = `11111001111100`\n",
    "- BeH2 = `11100001110000`\n",
    "- NH3 = `1111100011111000`\n",
    "You can retrieve them by calling `Hamiltonian.read_bitstring_HF()`\n",
    "\n",
    "Consider the set of influential pairs:\n",
    "\\begin{align}\n",
    "    \\mathcal{I}_\\mathrm{comp}\n",
    "    =\n",
    "    \\left\\{\\left.\n",
    "        (\\Qarrow,\\Rarrow)\n",
    "        \\,\\right|\\,\n",
    "        \\textrm{for all $i$, either $Q_i=R_i$, or $\\{Q_i,R_i\\}=\\{I,Z\\}$}\n",
    "    \\right\\}\n",
    "\\end{align}\n",
    "\n",
    "Then the cost function to optimise will be:\n",
    "\\begin{align}\n",
    "    \\mathrm{cost}(\\{\\beta_i\\}_{i=1}^n)\n",
    "    =\n",
    "    \\sum_{\\Qarrow,\\Rarrow\\in\\mathcal{I}_\\mathrm{comp}}\n",
    "        \\alpha_\\Qarrow\n",
    "        \\alpha_\\Rarrow\n",
    "        \\prod_{i | Q_i=R_i\\neq I}\n",
    "            \\beta_{i,Q_i}^{-1}\n",
    "        \\prod_{i | Q_i\\neq R_i}\n",
    "            m_i\n",
    "\\end{align}\n",
    "\n",
    "Warning, the small Hamiltonians don't follow the pattern because they use other reduction techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitstring_HF = ham.read_bitstring_HF()\n",
    "β = ham.pauli_rep.local_dists_optimal('mixed', 'scipy', bitstring_HF=bitstring_HF)\n",
    "print(ham.pauli_rep.variance_local(energy, state, β))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance after LDF grouping\n",
    "\n",
    "We should use 1-norm sampling for $\\kappa$\n",
    "\n",
    "\\begin{align}\n",
    "    \\Var[\\nu] \n",
    "    = \n",
    "    \\left(\n",
    "    \\sum_{k=1}^{n_c}\n",
    "        \\frac1{\\kappa_k} \n",
    "        \\sum_{\\Qarrow,\\Rarrow\\in C^{(k)}}\n",
    "            \\alpha_\\Qarrow\\alpha_\\Rarrow\n",
    "            \\prod_{i\\in\\supp(\\Qarrow\\Rarrow)} \\langle \\Qarrow\\Rarrow \\rangle\n",
    "    \\right)\n",
    "    - \\langle H_0 \\rangle^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from var import variance_ldf, kappa_1norm #kappa_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = ham.ldf()\n",
    "kappa = kappa_1norm(ldf)\n",
    "energy_tf = ham.pauli_rep.energy_tf(energy)\n",
    "variance_ldf(ldf, state, kappa, energy_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variances_dict(ham, β_diag=None, β_mix=None):\n",
    "    pr = ham.pauli_rep\n",
    "    dic = {}\n",
    "    \n",
    "    energy, state = pr.ground(multithread=True)\n",
    "    print(\"energy :\", energy)\n",
    "\n",
    "    # ell_1\n",
    "    var = pr.variance_ell_1(energy)\n",
    "    print(\"ell 1: \", var)\n",
    "    dic['ell_1'] = var\n",
    "    \n",
    "    # LDF with 1-norm sampling\n",
    "    ldf = ham.ldf()\n",
    "    kappa = kappa_1norm(ldf)\n",
    "    energy_tf = pr.energy_tf(energy)\n",
    "    var = variance_ldf(ldf, state, kappa, energy_tf)\n",
    "    print(\"ldf 1norm: \", var)\n",
    "    dic['ldf_1norm'] = var\n",
    "    \n",
    "    # uniform\n",
    "    β_uniform = pr.local_dists_uniform()\n",
    "    var = pr.variance_local(energy, state, β_uniform, multithread=True)\n",
    "    print(\"uniform: \", var)\n",
    "    dic['uniform'] = var\n",
    "    \n",
    "    # optimal (diagonal)\n",
    "    if β_diag is not None:\n",
    "        var = pr.variance_local(energy, state, β_diag, multithread=True)\n",
    "        print(\"optimal diagonal: \", var)\n",
    "        dic['optimal_diag'] = var\n",
    " \n",
    "    # optimal (mixed)\n",
    "    if β_mix is not None:\n",
    "        var = pr.variance_local(energy, state, β_mix, multithread=True)\n",
    "        print(\"optimal mixed: \", var)\n",
    "        dic['optimal_mix'] = var\n",
    "    \n",
    "    return dic\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def variances_graph(variances):\n",
    "    num_variances = len(variances)\n",
    "    x = range(num_variances)\n",
    "    height = list(variances.values())\n",
    "\n",
    "    plt.bar(x, height)\n",
    "    plt.xticks(x, list(variances.keys()), rotation=20)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_ALL = {}\n",
    "beta_optimal_ALL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'h2_jw_4'\n",
    "ham = h2_jw_4\n",
    "bitstring_HF = ham.read_bitstring_HF()\n",
    "\n",
    "title = \"Variances for various algorithms on H2 in JW encoding over 4 qubits\"\n",
    "\n",
    "%time β_diag = ham.pauli_rep.local_dists_optimal('diagonal')\n",
    "%time β_mix = ham.pauli_rep.local_dists_optimal('mixed', bitstring_HF)\n",
    "beta_optimal_ALL[name] = {'diagonal': β_diag, 'mixed': β_mix}\n",
    "\n",
    "%time variances_ALL[name] = variances_dict(ham, β_diag=β_diag, β_mix=β_mix)\n",
    "\n",
    "print(\"=====\")\n",
    "print(title)\n",
    "print(\"=====\")\n",
    "variances_ALL[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_graph(variances_ALL[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'h2_jw'\n",
    "ham = h2_jw\n",
    "bitstring_HF = ham.read_bitstring_HF()\n",
    "\n",
    "title = \"Variances for various algorithms on H2 in JW encoding over 8 qubits\"\n",
    "\n",
    "%time β_diag = ham.pauli_rep.local_dists_optimal('diagonal')\n",
    "%time β_mix = ham.pauli_rep.local_dists_optimal('mixed', bitstring_HF)\n",
    "beta_optimal_ALL[name] = {'diagonal': β_diag, 'mixed': β_mix}\n",
    "\n",
    "%time variances_ALL[name] = variances_dict(ham, β_diag=β_diag, β_mix=β_mix)\n",
    "\n",
    "print(\"=====\")\n",
    "print(title)\n",
    "print(\"=====\")\n",
    "variances_ALL[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_graph(variances_ALL[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lih_jw'\n",
    "ham = lih_jw\n",
    "bitstring_HF = ham.read_bitstring_HF()\n",
    "\n",
    "title = \"Variances for various algorithms on LiH in JW encoding over 12 qubits\"\n",
    "\n",
    "%time β_diag = ham.pauli_rep.local_dists_optimal('diagonal')\n",
    "%time β_mix = ham.pauli_rep.local_dists_optimal('mixed', bitstring_HF)\n",
    "beta_optimal_ALL[name] = {'diagonal': β_diag, 'mixed': β_mix}\n",
    "\n",
    "%time variances_ALL[name] = variances_dict(ham, β_diag=β_diag, β_mix=β_mix)\n",
    "\n",
    "print(\"=====\")\n",
    "print(title)\n",
    "print(\"=====\")\n",
    "variances_ALL[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_graph(variances_ALL[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'h2o_jw'\n",
    "ham = h2o_jw\n",
    "bitstring_HF = ham.read_bitstring_HF()\n",
    "\n",
    "title = \"Variances for various algorithms on H2O in JW encoding over 14 qubits\"\n",
    "\n",
    "%time β_diag = ham.pauli_rep.local_dists_optimal('diagonal')\n",
    "%time β_mix = ham.pauli_rep.local_dists_optimal('mixed', bitstring_HF)\n",
    "beta_optimal_ALL[name] = {'diagonal': β_diag, 'mixed': β_mix}\n",
    "\n",
    "%time variances_ALL[name] = variances_dict(ham, β_diag=β_diag, β_mix=β_mix)\n",
    "\n",
    "print(\"=====\")\n",
    "print(title)\n",
    "print(\"=====\")\n",
    "variances_ALL[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_graph(variances_ALL[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mac book pro is too weak for this!\n",
    "\n",
    "#name = 'nh3_jw'\n",
    "#ham = nh3_jw\n",
    "#bitstring_HF = ham.read_bitstring_HF()\n",
    "\n",
    "#title = \"Variances for various algorithms on ammonia in JW encoding over 14 qubits\"\n",
    "\n",
    "#%time β_diag = ham.pauli_rep.local_dists_optimal('diagonal')\n",
    "# rudy needs to help me! this will take too long using my pedestrian approach\n",
    "#%time β_mix = ham.pauli_rep.local_dists_optimal('mixed', bitstring_HF)\n",
    "#beta_optimal_ALL[name] = {'diagonal': β_diag, 'mixed': β_mix}\n",
    "\n",
    "#%time variances_ALL[name] = variances_dict(ham, β_diag=β_diag)#, β_mix=β_mix)\n",
    "\n",
    "#print(\"=====\")\n",
    "#print(title)\n",
    "#print(\"=====\")\n",
    "#variances_ALL[name]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
