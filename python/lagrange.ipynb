{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonian import HamiltonianSmall, Hamiltonian\n",
    "from var_opt import objective_diagonal\n",
    "\n",
    "import var_opt_lagrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrange by Rudy\n",
    "\n",
    "See Rudy's note on optimizing the variance with Lagrange multiplier method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lih_small = HamiltonianSmall('LiH', 1.5) # this encoding uses reduction techniques\n",
    "beh2_small = HamiltonianSmall('BeH2', 1.3) # this encoding uses reduction techniques\n",
    "\n",
    "# 4 qubits\n",
    "h2_jw_4 = Hamiltonian('H2_STO3g_4qubits', 'jw')\n",
    "h2_parity_4 = Hamiltonian('H2_STO3g_4qubits', 'parity')\n",
    "h2_bk_4 = Hamiltonian('H2_STO3g_4qubits', 'bk')\n",
    "\n",
    "# 8 qubits\n",
    "h2_jw = Hamiltonian('H2_6-31G_8qubits', 'jw')\n",
    "h2_parity = Hamiltonian('H2_6-31G_8qubits', 'parity')\n",
    "h2_bk = Hamiltonian('H2_6-31G_8qubits', 'bk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltonians = {\"lih_small\": lih_small,\n",
    "                \"beh2_small\": beh2_small,\n",
    "                \"h2_jw_4\": h2_jw_4,\n",
    "                \"h2_parity_4\": h2_parity_4,\n",
    "                \"h2_bk_4\": h2_bk_4,\n",
    "                \"h2_jw\": h2_jw,\n",
    "                \"h2_parity\": h2_parity,\n",
    "                \"h2_bk\": h2_bk}           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example showing how to call this from `Hamiltonian.PauliRep.local_dists_optimal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "def isProbability(betas, tol=1.0e-5):\n",
    "    \"\"\"\n",
    "        Check if betas are probabilities\n",
    "    \"\"\"\n",
    "    for k,v in betas.items():\n",
    "        for _v in v:\n",
    "            if _v < 0:\n",
    "                return False\n",
    "        if np.abs(np.sum(v) - 1.0) > tol:\n",
    "            print(\"\\tErr:\", np.abs(np.sum(v) - 1.0) )\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_rand_betas(nQubits):\n",
    "    \"\"\"\n",
    "        generate random initial points to search for betas\n",
    "    \"\"\"\n",
    "    betas = {}\n",
    "    for n in range(nQubits):\n",
    "        betas[n] = rand(3)\n",
    "        betas[n] = betas[n]/np.sum(betas[n])\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal: 1.8555830498849546\n",
      "Trial: 0 Mixed: 1.8546562200043257\n",
      "\tBetas: {0: [0.30257725605404756, 0.30257725605404756, 0.3948454878919052], 1: [0.3145814335670787, 0.3145814335670787, 0.37083713286584297], 2: [0.30257725605404756, 0.30257725605404756, 0.3948454878919052], 3: [0.3145814335670787, 0.3145814335670787, 0.3708371328658429]}\n",
      "\n",
      "\n",
      "Trial: 1 Mixed: 1.85465625858608\n",
      "\tBetas: {0: [0.3025992578644691, 0.30253491957050804, 0.3948658225650232], 1: [0.3145592428094682, 0.3146261385978969, 0.3708146185926352], 2: [0.3025426516043169, 0.3025915288373723, 0.39486581955831096], 3: [0.31461589474987073, 0.3145650756870394, 0.3708190295630901]}\n",
      "\n",
      "\n",
      "Trial: 2 Mixed: 1.85465625906689\n",
      "\tBetas: {0: [0.30253772809709073, 0.30259537691242716, 0.3948668949904824], 1: [0.31462256149399087, 0.31456262081819386, 0.3708148176878154], 2: [0.30259572323224004, 0.3025389395902336, 0.39486533717752675], 3: [0.31456135941759444, 0.3146203990915848, 0.37081824149082104]}\n",
      "\n",
      "\n",
      "Trial: 3 Mixed: 1.8546562606384822\n",
      "\tBetas: {0: [0.3025850006662837, 0.3025502068746176, 0.3948647924590992], 1: [0.3145747994436895, 0.31461097620267514, 0.37081422435363576], 2: [0.30252762006445716, 0.3026050180451836, 0.3948673618903595], 3: [0.3146307810243574, 0.3145503074155806, 0.37081891156006247]}\n",
      "\n",
      "\n",
      "Trial: 4 Mixed: 1.8546562615686812\n",
      "\tBetas: {0: [0.30253372937488693, 0.30260096053893193, 0.3948653100861815], 1: [0.3146268687904877, 0.3145569658319375, 0.3708161653775751], 2: [0.30253852602095826, 0.3025949752102756, 0.39486649876876645], 3: [0.3146206889416443, 0.3145619964081221, 0.37081731465023365]}\n",
      "\n",
      "\n",
      "Trial: 5 Mixed: 1.8546562616080209\n",
      "\tBetas: {0: [0.3026102376327043, 0.30252353263146203, 0.39486622973583385], 1: [0.31454673438687514, 0.3146368854208451, 0.37081638019227997], 2: [0.3025683581781646, 0.30256541503906803, 0.3948662267827677], 3: [0.31459024312679923, 0.31459330323808554, 0.3708164536351155]}\n",
      "\n",
      "\n",
      "Trial: 6 Mixed: 1.854656258661393\n",
      "\tBetas: {0: [0.30254280484139334, 0.30259156259323566, 0.3948656325653711], 1: [0.31461721175442237, 0.3145665162889922, 0.3708162719565856], 2: [0.30253491804691307, 0.3025986109234869, 0.39486647102960043], 3: [0.31462465425084085, 0.3145584300374692, 0.3708169157116902]}\n",
      "\n",
      "\n",
      "Trial: 7 Mixed: 1.8546562586594537\n",
      "\tBetas: {0: [0.3025885604479669, 0.30254409874949456, 0.3948673408025389], 1: [0.31456710713468533, 0.3146133354872024, 0.3708195573781126], 2: [0.3026014794427594, 0.302534123809573, 0.3948643967476677], 3: [0.3145579858345505, 0.3146280186110229, 0.3708139955544269]}\n",
      "\n",
      "\n",
      "Trial: 8 Mixed: 1.8546562586084945\n",
      "\tBetas: {0: [0.30260568313452824, 0.3025260825760758, 0.3948682342893963], 1: [0.3145492175716052, 0.3146319816718809, 0.370818800756514], 2: [0.30256349544117156, 0.30257276676208084, 0.39486373779674794], 3: [0.3145975607814198, 0.31458792101382055, 0.37081451820476]}\n",
      "\n",
      "\n",
      "Trial: 9 Mixed: 1.8546562593624354\n",
      "\tBetas: {0: [0.30259704898681905, 0.30253733683724826, 0.39486561417593313], 1: [0.31456018302929717, 0.314622267857223, 0.37081754911348], 2: [0.30253905212560717, 0.30259405835210534, 0.3948668895222878], 3: [0.3146209769715439, 0.3145637840551019, 0.37081523897335444]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ham = h2_jw_4\n",
    "energy, state = ham.pauli_rep.ground()\n",
    "\n",
    "objective = 'diagonal'\n",
    "method = 'lagrange'\n",
    "\n",
    "β_optimal_diagonal = ham.pauli_rep.local_dists_optimal(objective, method)\n",
    "\n",
    "var = ham.pauli_rep.variance_local(energy, state, β_optimal_diagonal)\n",
    "print(\"Diagonal:\", var)\n",
    "#print(\"\\tBetas:\", β_optimal_diagonal )\n",
    "\n",
    "objective = \"mixed\"\n",
    "bits_HF = ham.read_bitstring_HF()\n",
    "ntrials = 10\n",
    "for _ in range(ntrials): #because we do not have convexity, we perform several trials to look for optimal betas\n",
    "    if _ == 0:\n",
    "        beta_init = β_optimal_diagonal\n",
    "    else:\n",
    "        beta_init = get_rand_betas(ham.pauli_rep.num_qubits)\n",
    "    β_optimal_mixed = ham.pauli_rep.local_dists_optimal(objective, method, bitstring_HF=bits_HF, β_initial=beta_init)\n",
    "    if not isProbability(β_optimal_mixed ):\n",
    "        print(\"WARNING: not probability:\", β_optimal_mixed)\n",
    "    var = ham.pauli_rep.variance_local(energy, state, β_optimal_mixed)\n",
    "    print(\"Trial:\", _, \"Mixed:\", var)\n",
    "    print(\"\\tBetas:\", β_optimal_mixed)\n",
    "    print(\"\\n\")\n",
    "    #print(\"\\tBetas:\", β_optimal_diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal: 17.741947811137187\n",
      "Trial: 0 Mixed: 17.45718728202788\n",
      "\n",
      "\n",
      "Trial: 1 Mixed: 17.457191336127558\n",
      "\n",
      "\n",
      "Trial: 2 Mixed: 17.457191399347536\n",
      "\n",
      "\n",
      "Trial: 3 Mixed: 17.457192143682654\n",
      "\n",
      "\n",
      "Trial: 4 Mixed: 17.45719124671826\n",
      "\n",
      "\n",
      "Trial: 5 Mixed: 17.457190616009115\n",
      "\n",
      "\n",
      "Trial: 6 Mixed: 17.457191113903882\n",
      "\n",
      "\n",
      "Trial: 7 Mixed: 17.45719172291433\n",
      "\n",
      "\n",
      "Trial: 8 Mixed: 17.45719138908455\n",
      "\n",
      "\n",
      "Trial: 9 Mixed: 17.45719161926231\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ham = h2_jw\n",
    "energy, state = ham.pauli_rep.ground()\n",
    "\n",
    "objective = 'diagonal'\n",
    "method = 'lagrange'\n",
    "\n",
    "β_optimal_diagonal = ham.pauli_rep.local_dists_optimal(objective, method)\n",
    "\n",
    "var = ham.pauli_rep.variance_local(energy, state, β_optimal_diagonal)\n",
    "print(\"Diagonal:\", var)\n",
    "#print(\"\\tBetas:\", β_optimal_diagonal )\n",
    "\n",
    "objective = \"mixed\"\n",
    "bits_HF = ham.read_bitstring_HF()\n",
    "ntrials = 10\n",
    "for _ in range(ntrials): #because we do not have convexity, we perform several trials to look for optimal betas\n",
    "    if _ == 0:\n",
    "        beta_init = β_optimal_diagonal\n",
    "    else:\n",
    "        beta_init = get_rand_betas(ham.pauli_rep.num_qubits)\n",
    "    β_optimal_mixed = ham.pauli_rep.local_dists_optimal(objective, method, bitstring_HF=bits_HF, β_initial=beta_init)\n",
    "    if not isProbability(β_optimal_mixed ):\n",
    "        print(\"WARNING: not probability:\", β_optimal_mixed)\n",
    "    var = ham.pauli_rep.variance_local(energy, state, β_optimal_mixed)\n",
    "    print(\"Trial:\", _, \"Mixed:\", var)\n",
    "    print(\"\\n\")\n",
    "    #print(\"\\tBetas:\", β_optimal_diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of this code has been used to build into the function `find_optimal_beta_lagrange` which is called in the above `local_dists_optimal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_iterative_updates(tol=1.0e-5):\n",
    "    for name, ham in hamiltonians.items():\n",
    "        \n",
    "        print(\"Molecule=\", name, \"------------------\")\n",
    "        num_qubits = ham.pauli_rep.num_qubits\n",
    "        energy, state = ham.pauli_rep.ground()\n",
    "        # compare lagrange method with scipy method\n",
    "        β_opt = ham.pauli_rep.local_dists_optimal('diagonal', 'scipy')\n",
    "        # the cost function's value using scipy reference\n",
    "        objective = objective_diagonal(ham.pauli_rep.dic_tf, β_opt) \n",
    "         \n",
    "        # THIS IS THE EXPERIMENT WITH ITERATIVE UPDATES TO FIND BETAS \n",
    "        tol = 1.0e-5\n",
    "        iter = 0\n",
    "        β_old = None\n",
    "        while True and iter < 1000:\n",
    "            β_new, error = var_opt_lagrange.update_betas(ham.pauli_rep.dic_tf, num_qubits, β_old)\n",
    "            β_old = β_new\n",
    "            print(\"\\t\", iter, error)\n",
    "            iter += 1\n",
    "            if error < tol:\n",
    "                print(\"MOLECULE\", name, \"CONVERGE with error = \", error)\n",
    "                break\n",
    "\n",
    "        print(\"Distance from true values:\", var_opt_lagrange.distance(β_new, β_opt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_iterative_updates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "sum(rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagonal: 1.8555830498849475\n",
    "\tBetas: {0: [0.3021412813203303, 0.3021412813203303, 0.3957174373593399], 1: [0.31122347161788594, 0.31122347161788594, 0.3775530567642284], 2: [0.3021412813203302, 0.3021412813203302, 0.3957174373593399], 3: [0.31122347161788594, 0.31122347161788594, 0.3775530567642283]}\n",
    "Iter: 1000 Error: 0.003941286587053889\n",
    "Iter: 2000 Error: 0.016124144013247854\n",
    "Iter: 3000 Error: 0.0013773377918440202\n",
    "Iter: 4000 Error: 0.0005625655094954146\n",
    "Iter: 5000 Error: 0.16745325997376168\n",
    "Iter: 6000 Error: 0.0037267060386065175\n",
    "Iter: 7000 Error: 0.0010022833021886052\n",
    "Iter: 8000 Error: 0.014058898602006802\n",
    "Iter: 9000 Error: 0.009958090528469144\n",
    "Iter: 10000 Error: 0.00512673159169223\n",
    "Trial: 0 Mixed: 2.543555046805095\n",
    "Iter: 1000 Error: 0.003585242723138465\n",
    "Iter: 2000 Error: 0.0006914648612049422\n",
    "Iter: 3000 Error: 0.019647934158187063\n",
    "Iter: 4000 Error: 0.14023438689371548\n",
    "Iter: 5000 Error: 0.06919661838525358\n",
    "Iter: 6000 Error: 0.41345990820078754\n",
    "Iter: 7000 Error: 0.002178859090536059\n",
    "Iter: 8000 Error: 0.0011179009710741525\n",
    "Iter: 9000 Error: 0.0007945791951767325\n",
    "Iter: 10000 Error: 0.0005672610616211887\n",
    "Trial: 1 Mixed: 1.8039168252108944\n",
    "Iter: 1000 Error: 0.0007137036093656794\n",
    "Iter: 2000 Error: 0.009730865955007655\n",
    "Iter: 3000 Error: 0.002560873734534799\n",
    "Iter: 4000 Error: 0.0016906855997481894\n",
    "Iter: 5000 Error: 0.0028324585421971834\n",
    "Iter: 6000 Error: 0.000596670549329644\n",
    "Iter: 7000 Error: 0.001221240154815479\n",
    "Iter: 8000 Error: 0.001802810005417958\n",
    "Iter: 9000 Error: 0.04876421820803623\n",
    "Iter: 10000 Error: 0.05962252126462637\n",
    "Trial: 2 Mixed: -0.47124594133782327\n",
    "Iter: 1000 Error: 0.01662016838850315\n",
    "Iter: 2000 Error: 0.0005615385541332986\n",
    "Iter: 3000 Error: 0.0006200138185703638\n",
    "Iter: 4000 Error: 0.0030712525442489155\n",
    "Iter: 5000 Error: 0.0006403161420553304\n",
    "Iter: 6000 Error: 0.0020661182018662048\n",
    "Iter: 7000 Error: 0.0012115793422569293\n",
    "Iter: 8000 Error: 0.0006234949648077488\n",
    "Iter: 9000 Error: 0.003875781025590037\n",
    "Iter: 10000 Error: 0.0014577184675726414\n",
    "Trial: 3 Mixed: 1.789360660075212\n",
    "Iter: 1000 Error: 0.012008335525235989\n",
    "Iter: 2000 Error: 0.0014364311916412267\n",
    "Iter: 3000 Error: 0.012521399454954028\n",
    "Iter: 4000 Error: 0.0006407194758113205\n",
    "Iter: 5000 Error: 0.0005604531878207529\n",
    "Iter: 6000 Error: 0.02229275159923158\n",
    "Iter: 7000 Error: 0.000584561049029949\n",
    "Iter: 8000 Error: 0.031259360692849535\n",
    "Iter: 9000 Error: 0.029920644521126277\n",
    "Iter: 10000 Error: 0.9278196896893477\n",
    "Trial: 4 Mixed: 0.025781631119184745\n",
    "Iter: 1000 Error: 0.0007858044796963242\n",
    "Iter: 2000 Error: 0.009216318227607826\n",
    "Iter: 3000 Error: 0.049915401198954386\n",
    "Iter: 4000 Error: 0.0016604131216975604\n",
    "Iter: 5000 Error: 0.0007155061726851822\n",
    "Iter: 6000 Error: 0.009662142792307728\n",
    "Iter: 7000 Error: 0.003983315139492419\n",
    "Iter: 8000 Error: 0.004041784439071653\n",
    "Iter: 9000 Error: 0.010462345963707391\n",
    "Iter: 10000 Error: 0.0025057640738637074\n",
    "Trial: 5 Mixed: 1.8206407260865012\n",
    "Iter: 1000 Error: 0.0008473848239091968\n",
    "Iter: 2000 Error: 0.008947063585779846\n",
    "Iter: 3000 Error: 0.009341401079622134\n",
    "Iter: 4000 Error: 0.005610122767576232\n",
    "Iter: 5000 Error: 0.0016286986829575029\n",
    "Iter: 6000 Error: 0.0032632002012440535\n",
    "Iter: 7000 Error: 0.0007658496127080361\n",
    "Iter: 8000 Error: 0.028318429840387887\n",
    "Iter: 9000 Error: 0.0028227880340533054\n",
    "Iter: 10000 Error: 0.0012243209401208493\n",
    "Trial: 6 Mixed: 2.074844592316016\n",
    "Iter: 1000 Error: 0.026866154360524152\n",
    "Iter: 2000 Error: 0.02076632415773604\n",
    "Iter: 3000 Error: 0.0018929669909757915\n",
    "Iter: 4000 Error: 0.01282794114082728\n",
    "Iter: 5000 Error: 0.028568928618714826\n",
    "Iter: 6000 Error: 0.003688059707749385\n",
    "Iter: 7000 Error: 0.002081871310478431\n",
    "Iter: 8000 Error: 0.0349884222755818\n",
    "Iter: 9000 Error: 0.00133191439620874\n",
    "Iter: 10000 Error: 0.0035533288922693983\n",
    "Trial: 7 Mixed: 2.044075955500458\n",
    "Iter: 1000 Error: 0.02843167712425945\n",
    "Iter: 2000 Error: 0.006132341374506825\n",
    "Iter: 3000 Error: 0.0008297732679764637\n",
    "Iter: 4000 Error: 0.003963053241234429\n",
    "Iter: 5000 Error: 0.003227748616219524\n",
    "Iter: 6000 Error: 0.0008387669387437423\n",
    "Iter: 7000 Error: 0.0005910310942863078\n",
    "Iter: 8000 Error: 0.013268481342953123\n",
    "Iter: 9000 Error: 0.0008816996731647081\n",
    "Iter: 10000 Error: 0.0007684936682637051\n",
    "Trial: 8 Mixed: 1.9239192804531768\n",
    "Iter: 1000 Error: 0.02845800766269487\n",
    "Iter: 2000 Error: 0.13189651427015855\n",
    "Iter: 3000 Error: 0.009206329322852825\n",
    "Iter: 4000 Error: 0.0044196062182191445\n",
    "Iter: 5000 Error: 0.0008849940467915989\n",
    "Iter: 6000 Error: 0.01350533042122539\n",
    "Iter: 7000 Error: 0.0006028758341822034\n",
    "Iter: 8000 Error: 0.03208253244348048\n",
    "Iter: 9000 Error: 0.0014826342748445608\n",
    "Iter: 10000 Error: 0.01661578981761769\n",
    "Trial: 9 Mixed: 8.154931496417378\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit_keio",
   "language": "python",
   "name": "qiskit_keio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
